{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qHQuMV6VWYru"
      },
      "source": [
        "### Mount Drive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 77,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zt98eHYUWV-2",
        "outputId": "f8354e55-51d6-49ed-856c-760a5a71cbbb"
      },
      "outputs": [],
      "source": [
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AwrZ0ted69Tf"
      },
      "source": [
        "### Reading Dataset & Candidate Image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 78,
      "metadata": {
        "id": "p3ytYJTp4j3U"
      },
      "outputs": [],
      "source": [
        "import cv2 as cv\n",
        "\n",
        "# dataset = cv.imread(\"Dataset/Numbers_Template.png\")\n",
        "# candidate = cv.imread(\"Dataset/Numbers_9.png\")\n",
        "dataset = cv.imread(\"Dataset/Vowels_Template.png\")\n",
        "candidate = cv.imread(\"Dataset/Vowels_9.png\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 79,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 163
        },
        "id": "YC4JpM-r6pNo",
        "outputId": "e03ca5f0-6460-4aa9-c31d-b566bb6c9660"
      },
      "outputs": [],
      "source": [
        "# # from google.colab.patches import cv2_imshow\n",
        "\n",
        "# cv2_imshow(dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 80,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 144
        },
        "id": "doTr8V0w7QZw",
        "outputId": "a2327a3f-30ab-4cf0-fed8-b93e818255fc"
      },
      "outputs": [],
      "source": [
        "# cv2_imshow(candidate)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 81,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xJskSfGY8WyY",
        "outputId": "301c09d1-8385-4b99-ac9a-15df60eeede5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(148, 1295, 3)\n",
            "(147, 115, 3)\n"
          ]
        }
      ],
      "source": [
        "print(dataset.shape)\n",
        "print(candidate.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3tiquIaC7YwK"
      },
      "source": [
        "### Defining Size of Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 82,
      "metadata": {
        "id": "3Ebe6auY7b1m"
      },
      "outputs": [],
      "source": [
        "n = 11;"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z6mrLk4u7iIt"
      },
      "source": [
        "### Defining Height & Weight of Images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 83,
      "metadata": {
        "id": "-Q0Q_cwk7jvV"
      },
      "outputs": [],
      "source": [
        "m = 50\n",
        "dataset_height = m\n",
        "candidate_height = dataset_height\n",
        "dataset_weight = n * m\n",
        "candidate_weight = m"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-XNPl4Dh7sdF"
      },
      "source": [
        "### Resizing Images\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 84,
      "metadata": {
        "id": "HGkNu6kV7qwW"
      },
      "outputs": [],
      "source": [
        "candidate_rs = cv.resize(candidate, dsize=(candidate_weight, candidate_height))\n",
        "dataset_rs = cv.resize(dataset, dsize=(dataset_weight, dataset_height))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 85,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZF5sGCpv95R9",
        "outputId": "b99eae46-1961-4001-b32f-7f63c1911c65"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(50, 550, 3)\n",
            "(50, 50, 3)\n"
          ]
        }
      ],
      "source": [
        "print(dataset_rs.shape)\n",
        "print(candidate_rs.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 86,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "6Uu2poaO-pio",
        "outputId": "0f24c0c9-529e-4650-a605-aa607e8ef7fd"
      },
      "outputs": [],
      "source": [
        "# cv2_imshow(dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 87,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "3I0vpA-A-s3e",
        "outputId": "3a47d4c9-647a-477f-9700-ea63cf29f481"
      },
      "outputs": [],
      "source": [
        "# cv2_imshow(candidate)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5u1zQU-o_vT3"
      },
      "source": [
        "### Converting RGB Images to Grayscale"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 88,
      "metadata": {
        "id": "IT5hmYW1_tav"
      },
      "outputs": [],
      "source": [
        "dataset_gray = cv.cvtColor(dataset_rs, cv.COLOR_BGR2GRAY)\n",
        "candidate_gray = cv.cvtColor(candidate_rs, cv.COLOR_BGR2GRAY)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 89,
      "metadata": {},
      "outputs": [],
      "source": [
        "# cv2_imshow(dataset_gray)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 90,
      "metadata": {},
      "outputs": [],
      "source": [
        "# cv2_imshow(candidate_gray)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 91,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6N0HBMPTAiS4",
        "outputId": "dc1aadeb-1740-451b-e2af-a94bcd7c96c9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(50, 550)\n",
            "(50, 50)\n"
          ]
        }
      ],
      "source": [
        "print(dataset_gray.shape)\n",
        "print(candidate_gray.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xRCTzBiWA3xA"
      },
      "source": [
        "### Computing a Global Threshold Value from Grayscale Image(Using Otsu's Method) & Converting to Binary Image\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 92,
      "metadata": {
        "id": "h4gqoF4aBYaM"
      },
      "outputs": [],
      "source": [
        "ret1, candidate_threshold = cv.threshold(\n",
        "    candidate_gray, 0, 255, cv.THRESH_BINARY + cv.THRESH_OTSU\n",
        ")\n",
        "ret2, dataset_threshold = cv.threshold(\n",
        "    dataset_gray, 0, 255, cv.THRESH_BINARY + cv.THRESH_OTSU\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 93,
      "metadata": {
        "id": "oNs7ov9UHMho"
      },
      "outputs": [],
      "source": [
        "candidate_bw = candidate_threshold\n",
        "dataset_bw = dataset_threshold;"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 94,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "yVwNjw3gCh1A",
        "outputId": "3f7564de-d3fc-421d-ed7a-c4b6cb7d8b64"
      },
      "outputs": [],
      "source": [
        "# cv2_imshow(candidate_bw)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 95,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "FiqoJ-R-DBPW",
        "outputId": "44b1fa2b-f12d-49b1-c028-21f5d4b3563b"
      },
      "outputs": [],
      "source": [
        "# cv2_imshow(dataset_bw)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0gUXF6UfDkTw"
      },
      "source": [
        "### Computing Correlation Coefficient between Candidate & Each Image of Dataset\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 96,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BsiF6zz7Dpt3",
        "outputId": "317b6f95-d8fd-4e07-b864-8e34bca21b47"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.2744816\n",
            "0.31707343\n",
            "0.3069747\n",
            "0.41128367\n",
            "0.49222508\n",
            "0.37082544\n",
            "0.3665083\n",
            "0.47586837\n",
            "0.16534793\n",
            "0.8458994\n",
            "0.31579843\n"
          ]
        }
      ],
      "source": [
        "j = 0\n",
        "all_cc = []\n",
        "for i in range(0, n):\n",
        "    Image = dataset_bw[\n",
        "        0:candidate_height, j : j + candidate_weight\n",
        "    ]  # Cropping image one by one from dataset for template matching\n",
        "    # cv2_imshow(Image)\n",
        "    cc = cv.matchTemplate(\n",
        "        candidate_bw, Image, cv.TM_CCORR_NORMED\n",
        "    )  # Computing the correlation coefficient\n",
        "    print(cc[0][0])\n",
        "    all_cc.append(cc[0][0])\n",
        "    j = j + 50;"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 97,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yw_uzSQFJMz2",
        "outputId": "e0e0a364-a227-4675-dbb8-368bfadb2bc3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[0.2744816, 0.31707343, 0.3069747, 0.41128367, 0.49222508, 0.37082544, 0.3665083, 0.47586837, 0.16534793, 0.8458994, 0.31579843]\n"
          ]
        }
      ],
      "source": [
        "print(all_cc)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ujUzizyvMz_z"
      },
      "source": [
        "### Checking for the Value and Index of the Highest Correlation Coefficient"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 98,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pmHntGQpM3rP",
        "outputId": "cea589a9-c19f-4bd1-c90b-e23d78d6fdae"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Candidate Image Best Matched with  9  (  0.8458994  )\n"
          ]
        }
      ],
      "source": [
        "value = max(all_cc)\n",
        "index = all_cc.index(value)\n",
        "print(\"Candidate Image Best Matched with \", index, \" ( \", value, \" )\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0oj44BqSOqcZ"
      },
      "source": [
        "### Drawing a Boundary Box on the Dataset for Matched Candidate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 99,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "id": "6z0DRSjoO4Gb",
        "outputId": "450f883c-e862-49e9-9760-320b128f60e9"
      },
      "outputs": [],
      "source": [
        "dataset_marked = cv.rectangle(dataset_rs, (index * candidate_weight, 1), (index * candidate_weight + 50, 49), (0, 255, 0), 3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 100,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Matched Template with Boundary Box:\n"
          ]
        }
      ],
      "source": [
        "cv.imshow('dataset', dataset)\n",
        "cv.imshow('candidate', candidate)\n",
        "print(\"Matched Template with Boundary Box:\")\n",
        "cv.imshow('dataset_marked', dataset_marked)\n",
        "cv.waitKey(0) # waits for user to press any key (this is necessary to avoid Python kernel form crashing)\n",
        "cv.destroyAllWindows() #closing all open windows "
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "3tiquIaC7YwK",
        "Z6mrLk4u7iIt",
        "-XNPl4Dh7sdF",
        "5u1zQU-o_vT3",
        "xRCTzBiWA3xA",
        "0gUXF6UfDkTw"
      ],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.9.7 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7 (tags/v3.9.7:1016ef3, Aug 30 2021, 20:19:38) [MSC v.1929 64 bit (AMD64)]"
    },
    "vscode": {
      "interpreter": {
        "hash": "11938c6bc6919ae2720b4d5011047913343b08a43b18698fd82dedb0d4417594"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
